{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3df179-4bf2-446b-b24a-c1424311c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/home/kirilman/Project/asbestos/yolov5\")\n",
    "sys.path.append(\"/home/kirilman/Project/asbestos/\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from dataset.path_utils import get_files_from_dirs, get_paths_from_dirs\n",
    "from pycocotools.coco import COCO\n",
    "import pandas as pd\n",
    "from dataset import load_txt\n",
    "from yolov5.utils.general import xywhn2xyxy, xywh2xyxy, xyxy2xywh\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e6d6ed6-653d-4281-8c2c-4262e0402ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diag(coords):\n",
    "    if isinstance(coords, np.ndarray) and len(coords.shape) == 2:\n",
    "        x1 = coords[0,0]\n",
    "        y1 = coords[0,1]\n",
    "        x2 = coords[0,2]\n",
    "        y2 = coords[0,3]\n",
    "    else:\n",
    "        x1,y1,x2,y2 = coords\n",
    "    return np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "def get_bbox_size_arr(path_2_label, image_names = None):\n",
    "    labels_files = get_paths_from_dirs([path_2_label],['txt'])\n",
    "    if image_names:\n",
    "        labels_files = list(filter(lambda x: True if str(x.name).split('.')[0] in image_names else False, labels_files))\n",
    "    bbox_sizes = []\n",
    "    for p in labels_files:\n",
    "        data = np.loadtxt(p)\n",
    "        if len(data.shape) > 1:\n",
    "            bboxs = data[:,1:5]\n",
    "        else:\n",
    "            bboxs = data[1:5].reshape(1,-1)\n",
    "        for i,box in enumerate(xywh2xyxy(bboxs)):\n",
    "            bbox_sizes.append(get_diag(box))\n",
    "    return np.array(bbox_sizes)\n",
    "def ks_metric(a,b):\n",
    "    r = stats.kstest(a, b)\n",
    "    return {'statistic': r.statistic, 'pvalue': r.pvalue}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c1689d-15df-42d4-8ee4-e5ca9eb6745f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/yolov5s.pt, cfg=yolov5m.yaml, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_125633-36hakmcy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/36hakmcy\u001b[0m\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "YOLOv5m summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 57/481 items from ../../yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G     0.1078     0.2585          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788     0.0272      0.187     0.0171     0.0054\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.46G     0.1037     0.2577          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.028      0.192     0.0195    0.00556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.46G     0.1028     0.2793          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788     0.0211      0.145      0.014    0.00407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.46G     0.1004     0.2974          0        179        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788     0.0315      0.162     0.0175     0.0049\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.46G    0.09979     0.2721          0        332        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788     0.0351      0.184     0.0248    0.00633\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating ../../yolov5/runs/train/ks/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788     0.0351      0.184     0.0246    0.00633\n",
      "Results saved to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÖ‚ñÜ‚ñÅ‚ñÑ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÑ‚ñÑ‚ñÅ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñá‚ñà‚ñÅ‚ñÑ‚ñá‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñà‚ñÑ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÇ‚ñÅ‚ñà‚ñÜ‚ñÇ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñà‚ñà‚ñÅ‚ñÉ‚ñÜ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.02476\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.00633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.03512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.18401\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.02464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.00633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.03512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.18401\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.09979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.27214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.10334\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.32434\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mks\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/36hakmcy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 177 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221201_125633-36hakmcy/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ../../yolov5/train.py --cfg yolov5m.yaml --data \\\n",
    "../../../dataset/detection_set2/data_simple.yaml --imgs 512 --epoch 5 --name ks --batch-size 4 --exist-ok \\\n",
    "--project ../../yolov5/runs/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4120433-663e-4a37-ba79-0848f931e096",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/runs/train/ks/weights/last.pt, cfg=, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_130146-16bzygvp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/16bzygvp\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from ../../yolov5/runs/train/ks/weights/last.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G     0.0987     0.2712          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788     0.0343      0.217     0.0276    0.00747\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.46G    0.09702     0.2597          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788     0.0393      0.265     0.0324    0.00913\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.46G    0.09768      0.272          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788     0.0378       0.25     0.0263    0.00734\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.46G    0.09551     0.2855          0        179        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.049      0.317     0.0413      0.014\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.46G    0.09512      0.264          0        332        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788     0.0513      0.352      0.042     0.0123\n",
      "\n",
      "5 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating ../../yolov5/runs/train/ks/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788     0.0492      0.319     0.0417     0.0141\n",
      "Results saved to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÇ‚ñÑ‚ñÅ‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÅ‚ñÉ‚ñÅ‚ñà‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÅ‚ñÉ‚ñÇ‚ñá‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÅ‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñà‚ñÖ‚ñÜ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÑ‚ñÅ‚ñÑ‚ñà‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÜ‚ñÉ‚ñà‚ñÉ‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.04133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.01403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.04904\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.31726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.04171\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.0141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.04924\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.31853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.09512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.26403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.09378\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.3274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mks\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/16bzygvp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 180 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221201_130146-16bzygvp/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../../yolov5/runs/train/ks/weights/last.pt'], source=../../../dataset/detection_set2/validation/, data=../../yolov5/data/coco128.yaml, imgsz=[256, 256], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../../yolov5/runs/detect, name=ks, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/18 /home/kirilman/Project/dataset/detection_set2/validation/11-11-2021-12-27-13_7_1_73_detailed.bmp: 224x256 (no detections), 8.3ms\n",
      "image 2/18 /home/kirilman/Project/dataset/detection_set2/validation/27_13_38_18_16-03-2020_1.jpg: 224x256 (no detections), 5.7ms\n",
      "image 3/18 /home/kirilman/Project/dataset/detection_set2/validation/637411999957739159.bmp: 224x256 (no detections), 5.3ms\n",
      "image 4/18 /home/kirilman/Project/dataset/detection_set2/validation/637412028767035032.bmp: 224x256 (no detections), 6.1ms\n",
      "image 5/18 /home/kirilman/Project/dataset/detection_set2/validation/637412036419065712.bmp: 224x256 (no detections), 5.3ms\n",
      "image 6/18 /home/kirilman/Project/dataset/detection_set2/validation/637412037749791299.bmp: 224x256 (no detections), 5.3ms\n",
      "image 7/18 /home/kirilman/Project/dataset/detection_set2/validation/637412043190378663.bmp: 224x256 (no detections), 5.5ms\n",
      "image 8/18 /home/kirilman/Project/dataset/detection_set2/validation/8,46-00-637370577745395177.bmp: 224x256 (no detections), 5.4ms\n",
      "image 9/18 /home/kirilman/Project/dataset/detection_set2/validation/8,85-00-637370578761751298.bmp: 224x256 (no detections), 5.3ms\n",
      "image 10/18 /home/kirilman/Project/dataset/detection_set2/validation/9_11_53_29_16-03-2020_1.jpg: 224x256 (no detections), 5.3ms\n",
      "image 11/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_11_07_12.bmp: 224x256 5 rocks, 5.3ms\n",
      "image 12/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_11_32_300.bmp: 224x256 3 rocks, 5.4ms\n",
      "image 13/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_27_48_300.bmp: 224x256 9 rocks, 5.7ms\n",
      "image 14/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_10_30_16.bmp: 224x256 2 rocks, 5.7ms\n",
      "image 15/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_10.bmp: 224x256 11 rocks, 5.4ms\n",
      "image 16/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_31.bmp: 224x256 4 rocks, 5.6ms\n",
      "image 17/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_39.bmp: 224x256 4 rocks, 5.4ms\n",
      "image 18/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_13_37_47.bmp: 224x256 (no detections), 5.3ms\n",
      "Speed: 0.4ms pre-process, 5.6ms inference, 0.5ms NMS per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1m../../yolov5/runs/detect/ks\u001b[0m\n",
      "18 labels saved to ../../yolov5/runs/detect/ks/labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/runs/train/ks/weights/last.pt, cfg=, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_131847-38tg64la\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/38tg64la\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from ../../yolov5/runs/train/ks/weights/last.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G    0.09444     0.2639          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788     0.0713      0.311     0.0615     0.0161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.46G    0.09305     0.2569          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788     0.0744      0.199     0.0617      0.019\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.46G    0.09422     0.2699          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788       0.11       0.17     0.0663     0.0181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.46G     0.0914     0.2849          0        179        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.196      0.213      0.119     0.0325\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.46G    0.09059     0.2654          0        332        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.201       0.24      0.138     0.0409\n",
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating ../../yolov5/runs/train/ks/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.201      0.241       0.14      0.041\n",
      "Results saved to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñà‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñà‚ñÖ‚ñà‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÉ‚ñÅ‚ñÑ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÖ‚ñÖ‚ñà‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñÅ‚ñÇ‚ñà‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.13839\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.04089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.20053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.23985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.14023\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.20096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.24112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.09059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.26537\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.08772\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.33221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mks\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/38tg64la\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 180 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221201_131847-38tg64la/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../../yolov5/runs/train/ks/weights/last.pt'], source=../../../dataset/detection_set2/validation/, data=../../yolov5/data/coco128.yaml, imgsz=[256, 256], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../../yolov5/runs/detect, name=ks, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/18 /home/kirilman/Project/dataset/detection_set2/validation/11-11-2021-12-27-13_7_1_73_detailed.bmp: 224x256 (no detections), 13.8ms\n",
      "image 2/18 /home/kirilman/Project/dataset/detection_set2/validation/27_13_38_18_16-03-2020_1.jpg: 224x256 (no detections), 6.2ms\n",
      "image 3/18 /home/kirilman/Project/dataset/detection_set2/validation/637411999957739159.bmp: 224x256 3 rocks, 5.4ms\n",
      "image 4/18 /home/kirilman/Project/dataset/detection_set2/validation/637412028767035032.bmp: 224x256 4 rocks, 5.9ms\n",
      "image 5/18 /home/kirilman/Project/dataset/detection_set2/validation/637412036419065712.bmp: 224x256 4 rocks, 5.3ms\n",
      "image 6/18 /home/kirilman/Project/dataset/detection_set2/validation/637412037749791299.bmp: 224x256 7 rocks, 5.4ms\n",
      "image 7/18 /home/kirilman/Project/dataset/detection_set2/validation/637412043190378663.bmp: 224x256 5 rocks, 6.0ms\n",
      "image 8/18 /home/kirilman/Project/dataset/detection_set2/validation/8,46-00-637370577745395177.bmp: 224x256 2 rocks, 6.1ms\n",
      "image 9/18 /home/kirilman/Project/dataset/detection_set2/validation/8,85-00-637370578761751298.bmp: 224x256 4 rocks, 8.2ms\n",
      "image 10/18 /home/kirilman/Project/dataset/detection_set2/validation/9_11_53_29_16-03-2020_1.jpg: 224x256 (no detections), 5.4ms\n",
      "image 11/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_11_07_12.bmp: 224x256 (no detections), 5.3ms\n",
      "image 12/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_11_32_300.bmp: 224x256 1 rock, 9.3ms\n",
      "image 13/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_27_48_300.bmp: 224x256 2 rocks, 5.4ms\n",
      "image 14/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_10_30_16.bmp: 224x256 16 rocks, 5.3ms\n",
      "image 15/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_10.bmp: 224x256 20 rocks, 5.4ms\n",
      "image 16/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_31.bmp: 224x256 10 rocks, 5.3ms\n",
      "image 17/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_39.bmp: 224x256 12 rocks, 6.3ms\n",
      "image 18/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_13_37_47.bmp: 224x256 (no detections), 5.3ms\n",
      "Speed: 0.3ms pre-process, 6.4ms inference, 0.7ms NMS per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1m../../yolov5/runs/detect/ks\u001b[0m\n",
      "18 labels saved to ../../yolov5/runs/detect/ks/labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/runs/train/ks/weights/last.pt, cfg=, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_133856-2qqhexjx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/2qqhexjx\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from ../../yolov5/runs/train/ks/weights/last.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G    0.08954     0.2641          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.185      0.283      0.153     0.0456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.46G    0.08822     0.2582          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.187       0.27      0.142     0.0416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.46G    0.08979     0.2754          0        111        512:  \u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:11.395790, resuming normal operation.\n",
      "        2/4      1.46G    0.08971     0.2708          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.166      0.203      0.112     0.0328\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.46G    0.08657     0.2835          0        179        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.272      0.314      0.199     0.0557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.46G    0.08595     0.2637          0        332        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.153       0.27      0.107      0.035\n",
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating ../../yolov5/runs/train/ks/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.271      0.306      0.198     0.0556\n",
      "Results saved to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÑ‚ñÑ‚ñÅ‚ñà‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÖ‚ñÑ‚ñÅ‚ñà‚ñÇ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÉ‚ñÉ‚ñÇ‚ñà‚ñÅ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÜ‚ñÖ‚ñÅ‚ñà‚ñÖ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñà‚ñÖ‚ñà‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÉ‚ñÅ‚ñÑ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÑ‚ñÜ‚ñá‚ñÅ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñÇ‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.1989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.05567\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.27233\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.31393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.19798\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.27093\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.30584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.08595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.26372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.08399\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.32908\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mks\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/2qqhexjx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 180 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221201_133856-2qqhexjx/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../../yolov5/runs/train/ks/weights/last.pt'], source=../../../dataset/detection_set2/validation/, data=../../yolov5/data/coco128.yaml, imgsz=[256, 256], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../../yolov5/runs/detect, name=ks, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/18 /home/kirilman/Project/dataset/detection_set2/validation/11-11-2021-12-27-13_7_1_73_detailed.bmp: 224x256 4 rocks, 7.8ms\n",
      "image 2/18 /home/kirilman/Project/dataset/detection_set2/validation/27_13_38_18_16-03-2020_1.jpg: 224x256 7 rocks, 5.6ms\n",
      "image 3/18 /home/kirilman/Project/dataset/detection_set2/validation/637411999957739159.bmp: 224x256 3 rocks, 6.4ms\n",
      "image 4/18 /home/kirilman/Project/dataset/detection_set2/validation/637412028767035032.bmp: 224x256 5 rocks, 5.4ms\n",
      "image 5/18 /home/kirilman/Project/dataset/detection_set2/validation/637412036419065712.bmp: 224x256 3 rocks, 5.6ms\n",
      "image 6/18 /home/kirilman/Project/dataset/detection_set2/validation/637412037749791299.bmp: 224x256 5 rocks, 5.7ms\n",
      "image 7/18 /home/kirilman/Project/dataset/detection_set2/validation/637412043190378663.bmp: 224x256 5 rocks, 5.4ms\n",
      "image 8/18 /home/kirilman/Project/dataset/detection_set2/validation/8,46-00-637370577745395177.bmp: 224x256 6 rocks, 5.4ms\n",
      "image 9/18 /home/kirilman/Project/dataset/detection_set2/validation/8,85-00-637370578761751298.bmp: 224x256 15 rocks, 5.7ms\n",
      "image 10/18 /home/kirilman/Project/dataset/detection_set2/validation/9_11_53_29_16-03-2020_1.jpg: 224x256 9 rocks, 5.4ms\n",
      "image 11/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_11_07_12.bmp: 224x256 (no detections), 5.4ms\n",
      "image 12/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_11_32_300.bmp: 224x256 2 rocks, 5.4ms\n",
      "image 13/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_27_48_300.bmp: 224x256 1 rock, 5.4ms\n",
      "image 14/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_10_30_16.bmp: 224x256 10 rocks, 5.4ms\n",
      "image 15/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_10.bmp: 224x256 11 rocks, 5.4ms\n",
      "image 16/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_31.bmp: 224x256 9 rocks, 5.5ms\n",
      "image 17/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_39.bmp: 224x256 11 rocks, 7.7ms\n",
      "image 18/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_13_37_47.bmp: 224x256 1 rock, 6.5ms\n",
      "Speed: 0.2ms pre-process, 5.8ms inference, 0.7ms NMS per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1m../../yolov5/runs/detect/ks\u001b[0m\n",
      "18 labels saved to ../../yolov5/runs/detect/ks/labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/runs/train/ks/weights/last.pt, cfg=, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_134345-fyfp7a7o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/fyfp7a7o\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from ../../yolov5/runs/train/ks/weights/last.pt\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G    0.08474     0.2632          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.297      0.348      0.243     0.0705\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.45G    0.08327      0.257          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.203      0.214      0.133     0.0369\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.45G    0.08506     0.2699          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.226      0.312      0.183     0.0592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.45G     0.0828     0.2823          0        179        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.358      0.373      0.299     0.0961\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.45G    0.08159      0.262          0        332        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.284       0.34      0.215      0.072\n",
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating ../../yolov5/runs/train/ks/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.357      0.372      0.298     0.0959\n",
      "Results saved to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÜ‚ñÅ‚ñÉ‚ñà‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÖ‚ñÅ‚ñÑ‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÖ‚ñÅ‚ñÇ‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñá‚ñÅ‚ñÖ‚ñà‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñá‚ñÑ‚ñà‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñÇ‚ñá‚ñà‚ñÅ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.29874\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.09611\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.35784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.3731\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.29824\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.09589\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.35663\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.37183\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.08159\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.26197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.07977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.32411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mks\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/fyfp7a7o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 180 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221201_134345-fyfp7a7o/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../../yolov5/runs/train/ks/weights/last.pt'], source=../../../dataset/detection_set2/validation/, data=../../yolov5/data/coco128.yaml, imgsz=[256, 256], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../../yolov5/runs/detect, name=ks, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/18 /home/kirilman/Project/dataset/detection_set2/validation/11-11-2021-12-27-13_7_1_73_detailed.bmp: 224x256 2 rocks, 7.8ms\n",
      "image 2/18 /home/kirilman/Project/dataset/detection_set2/validation/27_13_38_18_16-03-2020_1.jpg: 224x256 14 rocks, 5.3ms\n",
      "image 3/18 /home/kirilman/Project/dataset/detection_set2/validation/637411999957739159.bmp: 224x256 11 rocks, 5.4ms\n",
      "image 4/18 /home/kirilman/Project/dataset/detection_set2/validation/637412028767035032.bmp: 224x256 19 rocks, 5.8ms\n",
      "image 5/18 /home/kirilman/Project/dataset/detection_set2/validation/637412036419065712.bmp: 224x256 3 rocks, 5.4ms\n",
      "image 6/18 /home/kirilman/Project/dataset/detection_set2/validation/637412037749791299.bmp: 224x256 11 rocks, 5.5ms\n",
      "image 7/18 /home/kirilman/Project/dataset/detection_set2/validation/637412043190378663.bmp: 224x256 15 rocks, 5.4ms\n",
      "image 8/18 /home/kirilman/Project/dataset/detection_set2/validation/8,46-00-637370577745395177.bmp: 224x256 7 rocks, 5.4ms\n",
      "image 9/18 /home/kirilman/Project/dataset/detection_set2/validation/8,85-00-637370578761751298.bmp: 224x256 26 rocks, 5.6ms\n",
      "image 10/18 /home/kirilman/Project/dataset/detection_set2/validation/9_11_53_29_16-03-2020_1.jpg: 224x256 9 rocks, 5.5ms\n",
      "image 11/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_11_07_12.bmp: 224x256 2 rocks, 5.3ms\n",
      "image 12/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_11_32_300.bmp: 224x256 7 rocks, 5.3ms\n",
      "image 13/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_27_48_300.bmp: 224x256 2 rocks, 6.0ms\n",
      "image 14/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_10_30_16.bmp: 224x256 18 rocks, 6.2ms\n",
      "image 15/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_10.bmp: 224x256 24 rocks, 5.6ms\n",
      "image 16/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_31.bmp: 224x256 13 rocks, 5.4ms\n",
      "image 17/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_39.bmp: 224x256 12 rocks, 5.5ms\n",
      "image 18/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_13_37_47.bmp: 224x256 (no detections), 5.4ms\n",
      "Speed: 0.2ms pre-process, 5.7ms inference, 0.6ms NMS per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1m../../yolov5/runs/detect/ks\u001b[0m\n",
      "18 labels saved to ../../yolov5/runs/detect/ks/labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/runs/train/ks/weights/last.pt, cfg=, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_134817-yk9slrlq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/yk9slrlq\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from ../../yolov5/runs/train/ks/weights/last.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G    0.08066     0.2605          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.377      0.391      0.321      0.101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.46G    0.07886     0.2538          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.271       0.28      0.183     0.0619\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.46G    0.08136     0.2673          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.367      0.339      0.278     0.0914\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.46G    0.07879     0.2793          0        179        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.414      0.423      0.363      0.124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.46G    0.07813     0.2598          0        332        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.361      0.439      0.323      0.106\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating ../../yolov5/runs/train/ks/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.414      0.423      0.364      0.124\n",
      "Results saved to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÜ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÖ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÜ‚ñÅ‚ñÜ‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÜ‚ñÅ‚ñÑ‚ñá‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñÜ‚ñÉ‚ñà‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.36279\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.12387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.41385\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.42259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.36369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.12368\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.41352\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.42259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.07813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.25975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.07691\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.31982\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mks\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/yk9slrlq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 180 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221201_134817-yk9slrlq/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../../yolov5/runs/train/ks/weights/last.pt'], source=../../../dataset/detection_set2/validation/, data=../../yolov5/data/coco128.yaml, imgsz=[256, 256], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../../yolov5/runs/detect, name=ks, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/18 /home/kirilman/Project/dataset/detection_set2/validation/11-11-2021-12-27-13_7_1_73_detailed.bmp: 224x256 4 rocks, 7.7ms\n",
      "image 2/18 /home/kirilman/Project/dataset/detection_set2/validation/27_13_38_18_16-03-2020_1.jpg: 224x256 12 rocks, 5.3ms\n",
      "image 3/18 /home/kirilman/Project/dataset/detection_set2/validation/637411999957739159.bmp: 224x256 24 rocks, 5.4ms\n",
      "image 4/18 /home/kirilman/Project/dataset/detection_set2/validation/637412028767035032.bmp: 224x256 40 rocks, 5.3ms\n",
      "image 5/18 /home/kirilman/Project/dataset/detection_set2/validation/637412036419065712.bmp: 224x256 15 rocks, 5.4ms\n",
      "image 6/18 /home/kirilman/Project/dataset/detection_set2/validation/637412037749791299.bmp: 224x256 31 rocks, 5.4ms\n",
      "image 7/18 /home/kirilman/Project/dataset/detection_set2/validation/637412043190378663.bmp: 224x256 34 rocks, 5.3ms\n",
      "image 8/18 /home/kirilman/Project/dataset/detection_set2/validation/8,46-00-637370577745395177.bmp: 224x256 20 rocks, 8.8ms\n",
      "image 9/18 /home/kirilman/Project/dataset/detection_set2/validation/8,85-00-637370578761751298.bmp: 224x256 33 rocks, 5.5ms\n",
      "image 10/18 /home/kirilman/Project/dataset/detection_set2/validation/9_11_53_29_16-03-2020_1.jpg: 224x256 14 rocks, 7.5ms\n",
      "image 11/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_11_07_12.bmp: 224x256 6 rocks, 5.4ms\n",
      "image 12/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_11_32_300.bmp: 224x256 16 rocks, 5.4ms\n",
      "image 13/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_27_48_300.bmp: 224x256 5 rocks, 5.4ms\n",
      "image 14/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_10_30_16.bmp: 224x256 53 rocks, 5.5ms\n",
      "image 15/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_10.bmp: 224x256 48 rocks, 5.4ms\n",
      "image 16/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_31.bmp: 224x256 22 rocks, 5.4ms\n",
      "image 17/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_39.bmp: 224x256 19 rocks, 5.6ms\n",
      "image 18/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_13_37_47.bmp: 224x256 33 rocks, 5.4ms\n",
      "Speed: 0.2ms pre-process, 5.8ms inference, 0.6ms NMS per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1m../../yolov5/runs/detect/ks\u001b[0m\n",
      "18 labels saved to ../../yolov5/runs/detect/ks/labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/runs/train/ks/weights/last.pt, cfg=, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_135232-1z8diy5b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/1z8diy5b\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from ../../yolov5/runs/train/ks/weights/last.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G     0.0774     0.2576          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.405      0.398      0.362      0.128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.46G    0.07538     0.2511          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788       0.43      0.423      0.369      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.46G     0.0783     0.2645          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.362      0.372      0.296      0.106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.46G    0.07624     0.2772          0        179        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.443       0.42      0.364      0.137\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.46G     0.0756     0.2579          0        332        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.411      0.439      0.356      0.123\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating ../../yolov5/runs/train/ks/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.441      0.419      0.364      0.137\n",
      "Results saved to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñá‚ñà‚ñÅ‚ñà‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÜ‚ñà‚ñÅ‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÖ‚ñá‚ñÅ‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÑ‚ñÜ‚ñÅ‚ñÜ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñÜ‚ñÅ‚ñà‚ñÉ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÅ‚ñÉ‚ñà‚ñÉ‚ñÅ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.36445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.13725\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.44282\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.42005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.36406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.13677\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.44079\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.41878\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0756\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.25793\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.31441\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mks\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/1z8diy5b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 180 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221201_135232-1z8diy5b/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../../yolov5/runs/train/ks/weights/last.pt'], source=../../../dataset/detection_set2/validation/, data=../../yolov5/data/coco128.yaml, imgsz=[256, 256], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../../yolov5/runs/detect, name=ks, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/18 /home/kirilman/Project/dataset/detection_set2/validation/11-11-2021-12-27-13_7_1_73_detailed.bmp: 224x256 8 rocks, 7.7ms\n",
      "image 2/18 /home/kirilman/Project/dataset/detection_set2/validation/27_13_38_18_16-03-2020_1.jpg: 224x256 15 rocks, 5.4ms\n",
      "image 3/18 /home/kirilman/Project/dataset/detection_set2/validation/637411999957739159.bmp: 224x256 48 rocks, 5.4ms\n",
      "image 4/18 /home/kirilman/Project/dataset/detection_set2/validation/637412028767035032.bmp: 224x256 70 rocks, 5.4ms\n",
      "image 5/18 /home/kirilman/Project/dataset/detection_set2/validation/637412036419065712.bmp: 224x256 57 rocks, 5.4ms\n",
      "image 6/18 /home/kirilman/Project/dataset/detection_set2/validation/637412037749791299.bmp: 224x256 61 rocks, 5.4ms\n",
      "image 7/18 /home/kirilman/Project/dataset/detection_set2/validation/637412043190378663.bmp: 224x256 71 rocks, 8.0ms\n",
      "image 8/18 /home/kirilman/Project/dataset/detection_set2/validation/8,46-00-637370577745395177.bmp: 224x256 43 rocks, 5.5ms\n",
      "image 9/18 /home/kirilman/Project/dataset/detection_set2/validation/8,85-00-637370578761751298.bmp: 224x256 67 rocks, 5.7ms\n",
      "image 10/18 /home/kirilman/Project/dataset/detection_set2/validation/9_11_53_29_16-03-2020_1.jpg: 224x256 17 rocks, 6.0ms\n",
      "image 11/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_11_07_12.bmp: 224x256 8 rocks, 5.7ms\n",
      "image 12/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_11_32_300.bmp: 224x256 42 rocks, 8.5ms\n",
      "image 13/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_27_48_300.bmp: 224x256 12 rocks, 6.1ms\n",
      "image 14/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_10_30_16.bmp: 224x256 113 rocks, 6.4ms\n",
      "image 15/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_10.bmp: 224x256 110 rocks, 5.4ms\n",
      "image 16/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_31.bmp: 224x256 53 rocks, 6.2ms\n",
      "image 17/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_39.bmp: 224x256 76 rocks, 5.4ms\n",
      "image 18/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_13_37_47.bmp: 224x256 45 rocks, 5.4ms\n",
      "Speed: 0.3ms pre-process, 6.1ms inference, 0.7ms NMS per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1m../../yolov5/runs/detect/ks\u001b[0m\n",
      "18 labels saved to ../../yolov5/runs/detect/ks/labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/runs/train/ks/weights/last.pt, cfg=, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_135901-3sfge6ik\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/3sfge6ik\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from ../../yolov5/runs/train/ks/weights/last.pt\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G     0.0749     0.2552          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.476      0.385      0.392      0.148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.45G    0.07284     0.2471          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.454      0.415      0.384      0.143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.45G    0.07593      0.262          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.399      0.404      0.344      0.125\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.45G    0.07396     0.2757          0        179        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788       0.46      0.442      0.387      0.154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.45G    0.07357     0.2569          0        332        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788       0.47      0.443      0.411      0.159\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating ../../yolov5/runs/train/ks/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.468      0.442      0.411      0.159\n",
      "Results saved to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÜ‚ñÖ‚ñÅ‚ñá‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñà‚ñÜ‚ñÅ‚ñá‚ñá‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÅ‚ñÖ‚ñÉ‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñÜ‚ñÅ‚ñà‚ñÑ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÅ‚ñÇ‚ñÇ‚ñà‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñÅ‚ñÇ‚ñà‚ñÇ‚ñÇ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.41113\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.15856\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.46962\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.44273\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.41104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.15885\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.46782\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.44162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.07357\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.25687\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.07291\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.3147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mks\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/3sfge6ik\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 180 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221201_135901-3sfge6ik/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../../yolov5/runs/train/ks/weights/last.pt'], source=../../../dataset/detection_set2/validation/, data=../../yolov5/data/coco128.yaml, imgsz=[256, 256], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../../yolov5/runs/detect, name=ks, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/18 /home/kirilman/Project/dataset/detection_set2/validation/11-11-2021-12-27-13_7_1_73_detailed.bmp: 224x256 4 rocks, 8.1ms\n",
      "image 2/18 /home/kirilman/Project/dataset/detection_set2/validation/27_13_38_18_16-03-2020_1.jpg: 224x256 12 rocks, 6.2ms\n",
      "image 3/18 /home/kirilman/Project/dataset/detection_set2/validation/637411999957739159.bmp: 224x256 14 rocks, 5.3ms\n",
      "image 4/18 /home/kirilman/Project/dataset/detection_set2/validation/637412028767035032.bmp: 224x256 21 rocks, 5.5ms\n",
      "image 5/18 /home/kirilman/Project/dataset/detection_set2/validation/637412036419065712.bmp: 224x256 13 rocks, 5.5ms\n",
      "image 6/18 /home/kirilman/Project/dataset/detection_set2/validation/637412037749791299.bmp: 224x256 16 rocks, 6.3ms\n",
      "image 7/18 /home/kirilman/Project/dataset/detection_set2/validation/637412043190378663.bmp: 224x256 25 rocks, 5.5ms\n",
      "image 8/18 /home/kirilman/Project/dataset/detection_set2/validation/8,46-00-637370577745395177.bmp: 224x256 16 rocks, 5.4ms\n",
      "image 9/18 /home/kirilman/Project/dataset/detection_set2/validation/8,85-00-637370578761751298.bmp: 224x256 16 rocks, 6.2ms\n",
      "image 10/18 /home/kirilman/Project/dataset/detection_set2/validation/9_11_53_29_16-03-2020_1.jpg: 224x256 14 rocks, 6.3ms\n",
      "image 11/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_11_07_12.bmp: 224x256 5 rocks, 5.3ms\n",
      "image 12/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_11_32_300.bmp: 224x256 13 rocks, 5.3ms\n",
      "image 13/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_27_48_300.bmp: 224x256 8 rocks, 5.3ms\n",
      "image 14/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_10_30_16.bmp: 224x256 42 rocks, 11.3ms\n",
      "image 15/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_10.bmp: 224x256 38 rocks, 5.4ms\n",
      "image 16/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_31.bmp: 224x256 19 rocks, 5.4ms\n",
      "image 17/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_39.bmp: 224x256 17 rocks, 5.4ms\n",
      "image 18/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_13_37_47.bmp: 224x256 27 rocks, 5.3ms\n",
      "Speed: 0.2ms pre-process, 6.1ms inference, 0.8ms NMS per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1m../../yolov5/runs/detect/ks\u001b[0m\n",
      "18 labels saved to ../../yolov5/runs/detect/ks/labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/runs/train/ks/weights/last.pt, cfg=, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_140519-2hvg1y5a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/2hvg1y5a\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from ../../yolov5/runs/train/ks/weights/last.pt\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G    0.07278     0.2534          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.477      0.445      0.431      0.171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.45G     0.0706     0.2443          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.378      0.371      0.298      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.45G    0.07442     0.2601          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.455      0.434      0.409      0.146\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.45G    0.07231     0.2737          0        179        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.486      0.447      0.425      0.167\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.45G    0.07181      0.255          0        332        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.446      0.453      0.392      0.146\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating ../../yolov5/runs/train/ks/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.476      0.444       0.43      0.171\n",
      "Results saved to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñà‚ñÅ‚ñá‚ñà‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñà‚ñÅ‚ñÖ‚ñá‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñá‚ñÅ‚ñÜ‚ñà‚ñÖ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñá‚ñÅ‚ñÜ‚ñá‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñÖ‚ñÅ‚ñà‚ñÑ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÅ‚ñà‚ñÉ‚ñÜ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñÅ‚ñÉ‚ñà‚ñÇ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.43075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.17102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.47688\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.44543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.43035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.17119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.47621\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.4442\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.07181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.25504\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.07148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.30734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mks\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/2hvg1y5a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 180 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221201_140519-2hvg1y5a/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../../yolov5/runs/train/ks/weights/last.pt'], source=../../../dataset/detection_set2/validation/, data=../../yolov5/data/coco128.yaml, imgsz=[256, 256], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../../yolov5/runs/detect, name=ks, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/18 /home/kirilman/Project/dataset/detection_set2/validation/11-11-2021-12-27-13_7_1_73_detailed.bmp: 224x256 5 rocks, 7.8ms\n",
      "image 2/18 /home/kirilman/Project/dataset/detection_set2/validation/27_13_38_18_16-03-2020_1.jpg: 224x256 12 rocks, 5.5ms\n",
      "image 3/18 /home/kirilman/Project/dataset/detection_set2/validation/637411999957739159.bmp: 224x256 20 rocks, 5.7ms\n",
      "image 4/18 /home/kirilman/Project/dataset/detection_set2/validation/637412028767035032.bmp: 224x256 36 rocks, 5.4ms\n",
      "image 5/18 /home/kirilman/Project/dataset/detection_set2/validation/637412036419065712.bmp: 224x256 23 rocks, 6.6ms\n",
      "image 6/18 /home/kirilman/Project/dataset/detection_set2/validation/637412037749791299.bmp: 224x256 31 rocks, 6.0ms\n",
      "image 7/18 /home/kirilman/Project/dataset/detection_set2/validation/637412043190378663.bmp: 224x256 42 rocks, 6.7ms\n",
      "image 8/18 /home/kirilman/Project/dataset/detection_set2/validation/8,46-00-637370577745395177.bmp: 224x256 21 rocks, 5.9ms\n",
      "image 9/18 /home/kirilman/Project/dataset/detection_set2/validation/8,85-00-637370578761751298.bmp: 224x256 21 rocks, 5.9ms\n",
      "image 10/18 /home/kirilman/Project/dataset/detection_set2/validation/9_11_53_29_16-03-2020_1.jpg: 224x256 15 rocks, 5.7ms\n",
      "image 11/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_11_07_12.bmp: 224x256 5 rocks, 6.5ms\n",
      "image 12/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_11_32_300.bmp: 224x256 17 rocks, 5.4ms\n",
      "image 13/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_27_48_300.bmp: 224x256 11 rocks, 5.5ms\n",
      "image 14/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_10_30_16.bmp: 224x256 60 rocks, 6.0ms\n",
      "image 15/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_10.bmp: 224x256 52 rocks, 6.4ms\n",
      "image 16/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_31.bmp: 224x256 26 rocks, 6.1ms\n",
      "image 17/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_39.bmp: 224x256 34 rocks, 5.8ms\n",
      "image 18/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_13_37_47.bmp: 224x256 47 rocks, 5.7ms\n",
      "Speed: 0.2ms pre-process, 6.0ms inference, 0.7ms NMS per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1m../../yolov5/runs/detect/ks\u001b[0m\n",
      "18 labels saved to ../../yolov5/runs/detect/ks/labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/runs/train/ks/weights/last.pt, cfg=, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_141006-2kkx97ym\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/2kkx97ym\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from ../../yolov5/runs/train/ks/weights/last.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G    0.07102     0.2514          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.472      0.402      0.404      0.163\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.46G    0.06865     0.2405          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.413      0.367      0.321       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.46G    0.07247     0.2577          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.456      0.387      0.343      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.46G    0.07076     0.2715          0        179        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.521      0.451      0.464      0.185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.46G     0.0703     0.2542          0        332        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.448      0.462      0.412      0.156\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating ../../yolov5/runs/train/ks/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.525      0.447      0.464      0.184\n",
      "Results saved to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÖ‚ñÅ‚ñÇ‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÜ‚ñÅ‚ñÉ‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÖ‚ñÅ‚ñÑ‚ñà‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÑ‚ñÅ‚ñÇ‚ñá‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñÖ‚ñÅ‚ñà‚ñÖ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÅ‚ñÖ‚ñà‚ñÇ‚ñÇ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñÅ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.46411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.18466\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.52093\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.45051\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.46442\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.18411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.5248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.44707\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0703\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.25418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.07175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.31888\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mks\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/2kkx97ym\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 180 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221201_141006-2kkx97ym/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../../yolov5/runs/train/ks/weights/last.pt'], source=../../../dataset/detection_set2/validation/, data=../../yolov5/data/coco128.yaml, imgsz=[256, 256], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../../yolov5/runs/detect, name=ks, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/18 /home/kirilman/Project/dataset/detection_set2/validation/11-11-2021-12-27-13_7_1_73_detailed.bmp: 224x256 2 rocks, 8.0ms\n",
      "image 2/18 /home/kirilman/Project/dataset/detection_set2/validation/27_13_38_18_16-03-2020_1.jpg: 224x256 11 rocks, 5.4ms\n",
      "image 3/18 /home/kirilman/Project/dataset/detection_set2/validation/637411999957739159.bmp: 224x256 13 rocks, 7.4ms\n",
      "image 4/18 /home/kirilman/Project/dataset/detection_set2/validation/637412028767035032.bmp: 224x256 24 rocks, 6.4ms\n",
      "image 5/18 /home/kirilman/Project/dataset/detection_set2/validation/637412036419065712.bmp: 224x256 21 rocks, 6.5ms\n",
      "image 6/18 /home/kirilman/Project/dataset/detection_set2/validation/637412037749791299.bmp: 224x256 22 rocks, 6.9ms\n",
      "image 7/18 /home/kirilman/Project/dataset/detection_set2/validation/637412043190378663.bmp: 224x256 37 rocks, 5.6ms\n",
      "image 8/18 /home/kirilman/Project/dataset/detection_set2/validation/8,46-00-637370577745395177.bmp: 224x256 21 rocks, 5.7ms\n",
      "image 9/18 /home/kirilman/Project/dataset/detection_set2/validation/8,85-00-637370578761751298.bmp: 224x256 15 rocks, 5.4ms\n",
      "image 10/18 /home/kirilman/Project/dataset/detection_set2/validation/9_11_53_29_16-03-2020_1.jpg: 224x256 13 rocks, 5.4ms\n",
      "image 11/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_11_07_12.bmp: 224x256 5 rocks, 5.6ms\n",
      "image 12/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_11_32_300.bmp: 224x256 13 rocks, 5.7ms\n",
      "image 13/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_27_48_300.bmp: 224x256 8 rocks, 5.5ms\n",
      "image 14/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_10_30_16.bmp: 224x256 39 rocks, 5.5ms\n",
      "image 15/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_10.bmp: 224x256 35 rocks, 8.6ms\n",
      "image 16/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_31.bmp: 224x256 19 rocks, 5.7ms\n",
      "image 17/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_39.bmp: 224x256 25 rocks, 5.6ms\n",
      "image 18/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_13_37_47.bmp: 224x256 37 rocks, 5.8ms\n",
      "Speed: 0.2ms pre-process, 6.1ms inference, 0.7ms NMS per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1m../../yolov5/runs/detect/ks\u001b[0m\n",
      "18 labels saved to ../../yolov5/runs/detect/ks/labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/runs/train/ks/weights/last.pt, cfg=, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_141440-3ubh14zo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/3ubh14zo\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from ../../yolov5/runs/train/ks/weights/last.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G    0.06936     0.2493          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.478      0.394      0.411      0.172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.46G     0.0671     0.2372          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.419      0.331      0.313      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.46G    0.07146     0.2553          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788        0.5      0.471      0.468      0.171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.46G    0.06933     0.2704          0        179        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.565      0.434       0.48      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.46G    0.06909      0.252          0        332        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.519      0.434       0.45      0.165\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating ../../yolov5/runs/train/ks/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.569      0.429      0.478      0.192\n",
      "Results saved to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÖ‚ñÅ‚ñà‚ñà‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÜ‚ñÅ‚ñÜ‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÑ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÑ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñÖ‚ñÅ‚ñà‚ñÖ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÑ‚ñÅ‚ñÖ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÅ‚ñà‚ñÅ‚ñÉ‚ñÇ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñÅ‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.48021\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.19293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.5654\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.43401\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.4782\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.19247\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.56892\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.42875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.06909\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.25202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.07292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.32887\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mks\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/3ubh14zo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 180 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221201_141440-3ubh14zo/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../../yolov5/runs/train/ks/weights/last.pt'], source=../../../dataset/detection_set2/validation/, data=../../yolov5/data/coco128.yaml, imgsz=[256, 256], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../../yolov5/runs/detect, name=ks, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/18 /home/kirilman/Project/dataset/detection_set2/validation/11-11-2021-12-27-13_7_1_73_detailed.bmp: 224x256 7 rocks, 8.0ms\n",
      "image 2/18 /home/kirilman/Project/dataset/detection_set2/validation/27_13_38_18_16-03-2020_1.jpg: 224x256 12 rocks, 5.3ms\n",
      "image 3/18 /home/kirilman/Project/dataset/detection_set2/validation/637411999957739159.bmp: 224x256 34 rocks, 5.5ms\n",
      "image 4/18 /home/kirilman/Project/dataset/detection_set2/validation/637412028767035032.bmp: 224x256 46 rocks, 5.6ms\n",
      "image 5/18 /home/kirilman/Project/dataset/detection_set2/validation/637412036419065712.bmp: 224x256 36 rocks, 6.0ms\n",
      "image 6/18 /home/kirilman/Project/dataset/detection_set2/validation/637412037749791299.bmp: 224x256 59 rocks, 5.4ms\n",
      "image 7/18 /home/kirilman/Project/dataset/detection_set2/validation/637412043190378663.bmp: 224x256 61 rocks, 8.4ms\n",
      "image 8/18 /home/kirilman/Project/dataset/detection_set2/validation/8,46-00-637370577745395177.bmp: 224x256 35 rocks, 5.5ms\n",
      "image 9/18 /home/kirilman/Project/dataset/detection_set2/validation/8,85-00-637370578761751298.bmp: 224x256 28 rocks, 8.4ms\n",
      "image 10/18 /home/kirilman/Project/dataset/detection_set2/validation/9_11_53_29_16-03-2020_1.jpg: 224x256 12 rocks, 5.4ms\n",
      "image 11/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_11_07_12.bmp: 224x256 7 rocks, 5.4ms\n",
      "image 12/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_11_32_300.bmp: 224x256 27 rocks, 5.7ms\n",
      "image 13/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_27_48_300.bmp: 224x256 17 rocks, 6.6ms\n",
      "image 14/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_10_30_16.bmp: 224x256 66 rocks, 6.2ms\n",
      "image 15/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_10.bmp: 224x256 66 rocks, 5.5ms\n",
      "image 16/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_31.bmp: 224x256 37 rocks, 7.9ms\n",
      "image 17/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_39.bmp: 224x256 63 rocks, 9.0ms\n",
      "image 18/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_13_37_47.bmp: 224x256 64 rocks, 5.8ms\n",
      "Speed: 0.3ms pre-process, 6.4ms inference, 0.8ms NMS per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1m../../yolov5/runs/detect/ks\u001b[0m\n",
      "18 labels saved to ../../yolov5/runs/detect/ks/labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/runs/train/ks/weights/last.pt, cfg=, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_142010-1m9rsjuw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/1m9rsjuw\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from ../../yolov5/runs/train/ks/weights/last.pt\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G    0.06806      0.247          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.554      0.429      0.459      0.194\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.45G    0.06562     0.2332          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.453      0.372      0.378      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.45G    0.06978     0.2532          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.503      0.457      0.434      0.168\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.45G    0.06802     0.2679          0        179        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.579       0.47      0.506       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.45G    0.06788     0.2503          0        332        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.511      0.439      0.447      0.172\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating ../../yolov5/runs/train/ks/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.579       0.47      0.506       0.21\n",
      "Results saved to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÖ‚ñÅ‚ñÑ‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÜ‚ñÅ‚ñÉ‚ñà‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñá‚ñÅ‚ñÑ‚ñà‚ñÑ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÖ‚ñÅ‚ñá‚ñà‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñÖ‚ñÅ‚ñà‚ñÖ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÑ‚ñÅ‚ñÖ‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÖ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.50599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.20958\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.57908\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.46954\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.5062\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.2103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.57908\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.46954\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.06788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.25028\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0691\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.31754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mks\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/1m9rsjuw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 180 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221201_142010-1m9rsjuw/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../../yolov5/runs/train/ks/weights/last.pt'], source=../../../dataset/detection_set2/validation/, data=../../yolov5/data/coco128.yaml, imgsz=[256, 256], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../../yolov5/runs/detect, name=ks, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/18 /home/kirilman/Project/dataset/detection_set2/validation/11-11-2021-12-27-13_7_1_73_detailed.bmp: 224x256 5 rocks, 7.7ms\n",
      "image 2/18 /home/kirilman/Project/dataset/detection_set2/validation/27_13_38_18_16-03-2020_1.jpg: 224x256 13 rocks, 7.8ms\n",
      "image 3/18 /home/kirilman/Project/dataset/detection_set2/validation/637411999957739159.bmp: 224x256 32 rocks, 5.4ms\n",
      "image 4/18 /home/kirilman/Project/dataset/detection_set2/validation/637412028767035032.bmp: 224x256 40 rocks, 5.4ms\n",
      "image 5/18 /home/kirilman/Project/dataset/detection_set2/validation/637412036419065712.bmp: 224x256 38 rocks, 5.5ms\n",
      "image 6/18 /home/kirilman/Project/dataset/detection_set2/validation/637412037749791299.bmp: 224x256 42 rocks, 5.5ms\n",
      "image 7/18 /home/kirilman/Project/dataset/detection_set2/validation/637412043190378663.bmp: 224x256 48 rocks, 5.7ms\n",
      "image 8/18 /home/kirilman/Project/dataset/detection_set2/validation/8,46-00-637370577745395177.bmp: 224x256 32 rocks, 5.5ms\n",
      "image 9/18 /home/kirilman/Project/dataset/detection_set2/validation/8,85-00-637370578761751298.bmp: 224x256 17 rocks, 5.4ms\n",
      "image 10/18 /home/kirilman/Project/dataset/detection_set2/validation/9_11_53_29_16-03-2020_1.jpg: 224x256 13 rocks, 5.4ms\n",
      "image 11/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_11_07_12.bmp: 224x256 7 rocks, 5.6ms\n",
      "image 12/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_11_32_300.bmp: 224x256 25 rocks, 5.4ms\n",
      "image 13/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_27_48_300.bmp: 224x256 14 rocks, 5.4ms\n",
      "image 14/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_10_30_16.bmp: 224x256 63 rocks, 5.4ms\n",
      "image 15/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_10.bmp: 224x256 67 rocks, 7.2ms\n",
      "image 16/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_31.bmp: 224x256 40 rocks, 5.6ms\n",
      "image 17/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_39.bmp: 224x256 60 rocks, 5.4ms\n",
      "image 18/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_13_37_47.bmp: 224x256 52 rocks, 5.5ms\n",
      "Speed: 0.2ms pre-process, 5.8ms inference, 0.7ms NMS per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1m../../yolov5/runs/detect/ks\u001b[0m\n",
      "18 labels saved to ../../yolov5/runs/detect/ks/labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/runs/train/ks/weights/last.pt, cfg=, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_142427-2ue775cs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/2ue775cs\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from ../../yolov5/runs/train/ks/weights/last.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G    0.06677     0.2442          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.572      0.422      0.467      0.197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.46G    0.06426      0.229          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.441      0.369      0.347      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.46G    0.06879     0.2487          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.545      0.428      0.451      0.179\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.46G     0.0669      0.265          0        179        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788       0.53      0.462      0.483      0.198\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.46G    0.06682     0.2484          0        332        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.528      0.456      0.488      0.202\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating ../../yolov5/runs/train/ks/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.526      0.454      0.487      0.202\n",
      "Results saved to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñá‚ñÅ‚ñÜ‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñà‚ñÅ‚ñÜ‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñà‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÖ‚ñÅ‚ñÖ‚ñà‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñÖ‚ñÅ‚ñà‚ñÖ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÑ‚ñÅ‚ñÖ‚ñà‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÅ‚ñà‚ñá‚ñÑ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñÅ‚ñà‚ñÑ‚ñÇ‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.48756\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.20178\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.52824\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.45613\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.48689\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.20191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.52614\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.45431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.06682\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.24842\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.06844\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.31753\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mks\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/2ue775cs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 180 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221201_142427-2ue775cs/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../../yolov5/runs/train/ks/weights/last.pt'], source=../../../dataset/detection_set2/validation/, data=../../yolov5/data/coco128.yaml, imgsz=[256, 256], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../../yolov5/runs/detect, name=ks, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/18 /home/kirilman/Project/dataset/detection_set2/validation/11-11-2021-12-27-13_7_1_73_detailed.bmp: 224x256 5 rocks, 7.7ms\n",
      "image 2/18 /home/kirilman/Project/dataset/detection_set2/validation/27_13_38_18_16-03-2020_1.jpg: 224x256 14 rocks, 5.4ms\n",
      "image 3/18 /home/kirilman/Project/dataset/detection_set2/validation/637411999957739159.bmp: 224x256 16 rocks, 5.3ms\n",
      "image 4/18 /home/kirilman/Project/dataset/detection_set2/validation/637412028767035032.bmp: 224x256 27 rocks, 6.5ms\n",
      "image 5/18 /home/kirilman/Project/dataset/detection_set2/validation/637412036419065712.bmp: 224x256 24 rocks, 5.4ms\n",
      "image 6/18 /home/kirilman/Project/dataset/detection_set2/validation/637412037749791299.bmp: 224x256 24 rocks, 6.6ms\n",
      "image 7/18 /home/kirilman/Project/dataset/detection_set2/validation/637412043190378663.bmp: 224x256 36 rocks, 5.5ms\n",
      "image 8/18 /home/kirilman/Project/dataset/detection_set2/validation/8,46-00-637370577745395177.bmp: 224x256 19 rocks, 5.4ms\n",
      "image 9/18 /home/kirilman/Project/dataset/detection_set2/validation/8,85-00-637370578761751298.bmp: 224x256 15 rocks, 5.7ms\n",
      "image 10/18 /home/kirilman/Project/dataset/detection_set2/validation/9_11_53_29_16-03-2020_1.jpg: 224x256 13 rocks, 7.0ms\n",
      "image 11/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_11_07_12.bmp: 224x256 5 rocks, 5.4ms\n",
      "image 12/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_11_32_300.bmp: 224x256 13 rocks, 5.8ms\n",
      "image 13/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_27_48_300.bmp: 224x256 12 rocks, 5.7ms\n",
      "image 14/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_10_30_16.bmp: 224x256 39 rocks, 6.5ms\n",
      "image 15/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_10.bmp: 224x256 44 rocks, 5.6ms\n",
      "image 16/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_31.bmp: 224x256 22 rocks, 5.8ms\n",
      "image 17/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_39.bmp: 224x256 33 rocks, 5.5ms\n",
      "image 18/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_13_37_47.bmp: 224x256 50 rocks, 5.9ms\n",
      "Speed: 0.2ms pre-process, 5.9ms inference, 0.7ms NMS per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1m../../yolov5/runs/detect/ks\u001b[0m\n",
      "18 labels saved to ../../yolov5/runs/detect/ks/labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/runs/train/ks/weights/last.pt, cfg=, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_143047-1571sq7z\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/1571sq7z\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from ../../yolov5/runs/train/ks/weights/last.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G    0.06567     0.2417          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.527      0.462      0.487      0.208\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.46G    0.06322     0.2246          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.475       0.42      0.423      0.172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.46G    0.06764     0.2466          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788       0.54      0.489      0.471      0.192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.46G    0.06597     0.2621          0        179        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.555      0.484      0.506      0.208\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.46G    0.06603     0.2461          0        332        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.532      0.439      0.469      0.193\n",
      "\n",
      "5 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating ../../yolov5/runs/train/ks/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.554      0.484      0.507      0.208\n",
      "Results saved to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÜ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñà‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÜ‚ñÅ‚ñá‚ñà‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÖ‚ñÅ‚ñà‚ñà‚ñÉ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñÖ‚ñÅ‚ñà‚ñÖ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÑ‚ñÅ‚ñÖ‚ñà‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÇ‚ñÖ‚ñà‚ñÅ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñÅ‚ñÇ‚ñá‚ñÉ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.5062\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.20774\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.55505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.48441\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.50738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.20822\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.55401\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.4835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.06603\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.24615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.31796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mks\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/1571sq7z\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 180 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221201_143047-1571sq7z/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../../yolov5/runs/train/ks/weights/last.pt'], source=../../../dataset/detection_set2/validation/, data=../../yolov5/data/coco128.yaml, imgsz=[256, 256], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../../yolov5/runs/detect, name=ks, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/18 /home/kirilman/Project/dataset/detection_set2/validation/11-11-2021-12-27-13_7_1_73_detailed.bmp: 224x256 8 rocks, 8.0ms\n",
      "image 2/18 /home/kirilman/Project/dataset/detection_set2/validation/27_13_38_18_16-03-2020_1.jpg: 224x256 13 rocks, 5.5ms\n",
      "image 3/18 /home/kirilman/Project/dataset/detection_set2/validation/637411999957739159.bmp: 224x256 23 rocks, 5.3ms\n",
      "image 4/18 /home/kirilman/Project/dataset/detection_set2/validation/637412028767035032.bmp: 224x256 42 rocks, 5.4ms\n",
      "image 5/18 /home/kirilman/Project/dataset/detection_set2/validation/637412036419065712.bmp: 224x256 55 rocks, 5.4ms\n",
      "image 6/18 /home/kirilman/Project/dataset/detection_set2/validation/637412037749791299.bmp: 224x256 60 rocks, 5.4ms\n",
      "image 7/18 /home/kirilman/Project/dataset/detection_set2/validation/637412043190378663.bmp: 224x256 45 rocks, 5.3ms\n",
      "image 8/18 /home/kirilman/Project/dataset/detection_set2/validation/8,46-00-637370577745395177.bmp: 224x256 33 rocks, 7.8ms\n",
      "image 9/18 /home/kirilman/Project/dataset/detection_set2/validation/8,85-00-637370578761751298.bmp: 224x256 15 rocks, 5.4ms\n",
      "image 10/18 /home/kirilman/Project/dataset/detection_set2/validation/9_11_53_29_16-03-2020_1.jpg: 224x256 14 rocks, 9.2ms\n",
      "image 11/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_11_07_12.bmp: 224x256 9 rocks, 5.3ms\n",
      "image 12/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_11_32_300.bmp: 224x256 21 rocks, 6.0ms\n",
      "image 13/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_27_48_300.bmp: 224x256 15 rocks, 8.9ms\n",
      "image 14/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_10_30_16.bmp: 224x256 61 rocks, 5.4ms\n",
      "image 15/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_10.bmp: 224x256 55 rocks, 5.4ms\n",
      "image 16/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_31.bmp: 224x256 28 rocks, 6.2ms\n",
      "image 17/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_39.bmp: 224x256 47 rocks, 6.9ms\n",
      "image 18/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_13_37_47.bmp: 224x256 46 rocks, 5.6ms\n",
      "Speed: 0.2ms pre-process, 6.3ms inference, 0.8ms NMS per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1m../../yolov5/runs/detect/ks\u001b[0m\n",
      "18 labels saved to ../../yolov5/runs/detect/ks/labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/runs/train/ks/weights/last.pt, cfg=, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_143530-1e8y6cfc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/1e8y6cfc\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from ../../yolov5/runs/train/ks/weights/last.pt\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G    0.06475     0.2389          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.569      0.428      0.481      0.208\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.45G    0.06218     0.2201          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.476      0.454      0.434      0.172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.45G    0.06684     0.2421          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.512      0.383      0.393      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.45G    0.06511     0.2588          0        179        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.559      0.489      0.522      0.231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.45G    0.06529     0.2444          0        332        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.525      0.478      0.489      0.213\n",
      "\n",
      "5 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating ../../yolov5/runs/train/ks/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.557      0.489      0.521      0.231\n",
      "Results saved to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÜ‚ñÉ‚ñÅ‚ñà‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÜ‚ñÉ‚ñÅ‚ñà‚ñÜ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñà‚ñÅ‚ñÑ‚ñá‚ñÖ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÑ‚ñÜ‚ñÅ‚ñà‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñÖ‚ñÅ‚ñà‚ñÖ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÑ‚ñÅ‚ñÖ‚ñà‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÉ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñÅ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.52162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.23111\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.55901\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.48904\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.52057\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.23065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.55659\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.48904\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.06529\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.24445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.06721\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.31194\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mks\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/1e8y6cfc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 180 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221201_143530-1e8y6cfc/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../../yolov5/runs/train/ks/weights/last.pt'], source=../../../dataset/detection_set2/validation/, data=../../yolov5/data/coco128.yaml, imgsz=[256, 256], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../../yolov5/runs/detect, name=ks, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/18 /home/kirilman/Project/dataset/detection_set2/validation/11-11-2021-12-27-13_7_1_73_detailed.bmp: 224x256 5 rocks, 8.0ms\n",
      "image 2/18 /home/kirilman/Project/dataset/detection_set2/validation/27_13_38_18_16-03-2020_1.jpg: 224x256 13 rocks, 7.8ms\n",
      "image 3/18 /home/kirilman/Project/dataset/detection_set2/validation/637411999957739159.bmp: 224x256 15 rocks, 5.4ms\n",
      "image 4/18 /home/kirilman/Project/dataset/detection_set2/validation/637412028767035032.bmp: 224x256 26 rocks, 5.5ms\n",
      "image 5/18 /home/kirilman/Project/dataset/detection_set2/validation/637412036419065712.bmp: 224x256 14 rocks, 5.5ms\n",
      "image 6/18 /home/kirilman/Project/dataset/detection_set2/validation/637412037749791299.bmp: 224x256 24 rocks, 5.5ms\n",
      "image 7/18 /home/kirilman/Project/dataset/detection_set2/validation/637412043190378663.bmp: 224x256 34 rocks, 7.9ms\n",
      "image 8/18 /home/kirilman/Project/dataset/detection_set2/validation/8,46-00-637370577745395177.bmp: 224x256 18 rocks, 5.6ms\n",
      "image 9/18 /home/kirilman/Project/dataset/detection_set2/validation/8,85-00-637370578761751298.bmp: 224x256 16 rocks, 5.5ms\n",
      "image 10/18 /home/kirilman/Project/dataset/detection_set2/validation/9_11_53_29_16-03-2020_1.jpg: 224x256 11 rocks, 5.5ms\n",
      "image 11/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_11_07_12.bmp: 224x256 4 rocks, 5.4ms\n",
      "image 12/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_11_32_300.bmp: 224x256 12 rocks, 5.6ms\n",
      "image 13/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_27_48_300.bmp: 224x256 10 rocks, 6.3ms\n",
      "image 14/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_10_30_16.bmp: 224x256 40 rocks, 5.6ms\n",
      "image 15/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_10.bmp: 224x256 43 rocks, 5.5ms\n",
      "image 16/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_31.bmp: 224x256 16 rocks, 5.9ms\n",
      "image 17/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_39.bmp: 224x256 28 rocks, 5.4ms\n",
      "image 18/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_13_37_47.bmp: 224x256 40 rocks, 5.4ms\n",
      "Speed: 0.2ms pre-process, 6.0ms inference, 0.7ms NMS per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1m../../yolov5/runs/detect/ks\u001b[0m\n",
      "18 labels saved to ../../yolov5/runs/detect/ks/labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/runs/train/ks/weights/last.pt, cfg=, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_143946-qo89apcy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/qo89apcy\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from ../../yolov5/runs/train/ks/weights/last.pt\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G    0.06379     0.2357          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.583      0.465       0.51      0.224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.45G    0.06089     0.2147          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.507      0.425      0.438      0.179\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.45G    0.06598     0.2408          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.537      0.464      0.458      0.194\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4      1.45G    0.06477     0.2554          0        179        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788       0.56       0.51      0.518       0.22\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4      1.45G    0.06493     0.2424          0        332        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.534      0.514      0.505      0.217\n",
      "\n",
      "5 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/last.pt, 42.1MB\n",
      "Optimizer stripped from ../../yolov5/runs/train/ks/weights/best.pt, 42.1MB\n",
      "\n",
      "Validating ../../yolov5/runs/train/ks/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.585      0.464      0.511      0.224\n",
      "Results saved to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñá‚ñÅ‚ñÉ‚ñà‚ñá‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñà‚ñÅ‚ñÉ‚ñá‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñà‚ñÅ‚ñÑ‚ñÜ‚ñÉ‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÑ‚ñÅ‚ñÑ‚ñà‚ñà‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñÖ‚ñÅ‚ñà‚ñÜ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÖ‚ñÅ‚ñÖ‚ñà‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÅ‚ñÖ‚ñà‚ñÅ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñÅ‚ñÑ‚ñÜ‚ñÇ‚ñà‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñÅ‚ñÜ‚ñà‚ñÉ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.51012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.22381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.58331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.46544\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.51078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.22432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.58488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.46447\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.06493\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.24236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.06606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.30315\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mks\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/qo89apcy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 180 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221201_143946-qo89apcy/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../../yolov5/runs/train/ks/weights/last.pt'], source=../../../dataset/detection_set2/validation/, data=../../yolov5/data/coco128.yaml, imgsz=[256, 256], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../../yolov5/runs/detect, name=ks, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/18 /home/kirilman/Project/dataset/detection_set2/validation/11-11-2021-12-27-13_7_1_73_detailed.bmp: 224x256 8 rocks, 8.3ms\n",
      "image 2/18 /home/kirilman/Project/dataset/detection_set2/validation/27_13_38_18_16-03-2020_1.jpg: 224x256 17 rocks, 5.5ms\n",
      "image 3/18 /home/kirilman/Project/dataset/detection_set2/validation/637411999957739159.bmp: 224x256 54 rocks, 5.4ms\n",
      "image 4/18 /home/kirilman/Project/dataset/detection_set2/validation/637412028767035032.bmp: 224x256 67 rocks, 9.3ms\n",
      "image 5/18 /home/kirilman/Project/dataset/detection_set2/validation/637412036419065712.bmp: 224x256 75 rocks, 5.5ms\n",
      "image 6/18 /home/kirilman/Project/dataset/detection_set2/validation/637412037749791299.bmp: 224x256 75 rocks, 5.4ms\n",
      "image 7/18 /home/kirilman/Project/dataset/detection_set2/validation/637412043190378663.bmp: 224x256 77 rocks, 8.0ms\n",
      "image 8/18 /home/kirilman/Project/dataset/detection_set2/validation/8,46-00-637370577745395177.bmp: 224x256 57 rocks, 5.4ms\n",
      "image 9/18 /home/kirilman/Project/dataset/detection_set2/validation/8,85-00-637370578761751298.bmp: 224x256 42 rocks, 5.6ms\n",
      "image 10/18 /home/kirilman/Project/dataset/detection_set2/validation/9_11_53_29_16-03-2020_1.jpg: 224x256 15 rocks, 5.5ms\n",
      "image 11/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_11_07_12.bmp: 224x256 18 rocks, 5.4ms\n",
      "image 12/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_11_32_300.bmp: 224x256 65 rocks, 5.5ms\n",
      "image 13/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualDetailedImage_12_27_48_300.bmp: 224x256 16 rocks, 5.4ms\n",
      "image 14/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_10_30_16.bmp: 224x256 74 rocks, 6.9ms\n",
      "image 15/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_10.bmp: 224x256 77 rocks, 5.7ms\n",
      "image 16/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_31.bmp: 224x256 48 rocks, 5.6ms\n",
      "image 17/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_12_44_39.bmp: 224x256 74 rocks, 8.3ms\n",
      "image 18/18 /home/kirilman/Project/dataset/detection_set2/validation/ManualGeneralImage_13_37_47.bmp: 224x256 59 rocks, 5.5ms\n",
      "Speed: 0.2ms pre-process, 6.2ms inference, 0.7ms NMS per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1m../../yolov5/runs/detect/ks\u001b[0m\n",
      "18 labels saved to ../../yolov5/runs/detect/ks/labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkirilman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../../yolov5/runs/train/ks/weights/last.pt, cfg=, data=../../../dataset/detection_set2/data_simple.yaml, hyp=../../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../../yolov5/runs/train/, name=ks, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 64 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.2-216-g6e544d5f Python-3.9.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5947MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../../yolov5/runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/kirilman/Project/asbestos/notebooks/Statistical test/wandb/run-20221201_144402-21lmqikw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kirilman/train/runs/21lmqikw\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 481/481 items from ../../yolov5/runs/train/ks/weights/last.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/train/labels.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/kirilman/Project/dataset/detection_set2/validation.cache' i\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../../yolov5/runs/train/ks/labels.jpg... \n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../../yolov5/runs/train/ks\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      1.29G    0.06307     0.2324          0        171        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788      0.615      0.437      0.505      0.222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4      1.46G    0.05994      0.209          0        196        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18        788       0.53      0.495       0.49      0.196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4      1.46G    0.06549     0.2358          0        197        512: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   "
     ]
    }
   ],
   "source": [
    "log_train = {}\n",
    "step = 5\n",
    "for epoch in range(2,20):\n",
    "    !python ../../yolov5/train.py --weights ../../yolov5/runs/train/ks/weights/last.pt --data \\\n",
    "    ../../../dataset/detection_set2/data_simple.yaml --imgs 512 --epoch {step} --name ks --batch-size 4 --exist-ok \\\n",
    "    --project ../../yolov5/runs/train/\n",
    "\n",
    "    !python ../../yolov5/detect.py --weights ../../yolov5/runs/train/ks/weights/last.pt --source ../../../dataset/detection_set2/validation/ --imgs 256 \\\n",
    "    --save-txt --name ks --exist-ok\n",
    "    \n",
    "    predict_labels = get_bbox_size_arr('../../yolov5/runs/detect/ks/labels/')\n",
    "    train_labels   = get_bbox_size_arr('../../../dataset/detection_set2/validation/')\n",
    "    r = ks_metric(predict_labels, train_labels)\n",
    "    log_train[epoch*step] = r\n",
    "    \n",
    "frame_log = pd.DataFrame(log_train).T\n",
    "frame_log.to_csv('ks_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13df18b3-54bf-476c-81b0-13b7b3971fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistic</th>\n",
       "      <th>pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.574208</td>\n",
       "      <td>6.618515e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.479775</td>\n",
       "      <td>5.242414e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.446310</td>\n",
       "      <td>3.601767e-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.428947</td>\n",
       "      <td>2.303558e-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.430259</td>\n",
       "      <td>1.907824e-70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.413814</td>\n",
       "      <td>4.337927e-77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.399461</td>\n",
       "      <td>2.875195e-78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.375050</td>\n",
       "      <td>7.095505e-75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    statistic        pvalue\n",
       "10   0.574208  6.618515e-07\n",
       "15   0.479775  5.242414e-13\n",
       "20   0.446310  3.601767e-30\n",
       "25   0.428947  2.303558e-49\n",
       "30   0.430259  1.907824e-70\n",
       "35   0.413814  4.337927e-77\n",
       "40   0.399461  2.875195e-78\n",
       "45   0.375050  7.095505e-75"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ddd43a36-ec6d-450d-8e71-b4ced9b4ff5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = 27\n",
    "arr = get_bbox_size_arr('../../yolov5/runs/detect/ks/labels/')\n",
    "train_arr = get_bbox_size_arr('../../../dataset/detection_set2/validation/')\n",
    "r = ks_metric(arr, train_arr)\n",
    "log_train[epoch] = r\n",
    "sns.histplot(arr)\n",
    "sns.histplot(train_arr, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f24289-c09a-476b-a8e6-0ee9c34e1ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: detect.py [-h] [--weights WEIGHTS [WEIGHTS ...]] [--source SOURCE]\n",
      "                 [--data DATA] [--imgsz IMGSZ [IMGSZ ...]]\n",
      "                 [--conf-thres CONF_THRES] [--iou-thres IOU_THRES]\n",
      "                 [--max-det MAX_DET] [--device DEVICE] [--view-img]\n",
      "                 [--save-txt] [--save-conf] [--save-crop] [--nosave]\n",
      "                 [--classes CLASSES [CLASSES ...]] [--agnostic-nms]\n",
      "                 [--augment] [--visualize] [--update] [--project PROJECT]\n",
      "                 [--name NAME] [--exist-ok] [--line-thickness LINE_THICKNESS]\n",
      "                 [--hide-labels] [--hide-conf] [--half] [--dnn]\n",
      "                 [--vid-stride VID_STRIDE]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --weights WEIGHTS [WEIGHTS ...]\n",
      "                        model path or triton URL\n",
      "  --source SOURCE       file/dir/URL/glob/screen/0(webcam)\n",
      "  --data DATA           (optional) dataset.yaml path\n",
      "  --imgsz IMGSZ [IMGSZ ...], --img IMGSZ [IMGSZ ...], --img-size IMGSZ [IMGSZ ...]\n",
      "                        inference size h,w\n",
      "  --conf-thres CONF_THRES\n",
      "                        confidence threshold\n",
      "  --iou-thres IOU_THRES\n",
      "                        NMS IoU threshold\n",
      "  --max-det MAX_DET     maximum detections per image\n",
      "  --device DEVICE       cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
      "  --view-img            show results\n",
      "  --save-txt            save results to *.txt\n",
      "  --save-conf           save confidences in --save-txt labels\n",
      "  --save-crop           save cropped prediction boxes\n",
      "  --nosave              do not save images/videos\n",
      "  --classes CLASSES [CLASSES ...]\n",
      "                        filter by class: --classes 0, or --classes 0 2 3\n",
      "  --agnostic-nms        class-agnostic NMS\n",
      "  --augment             augmented inference\n",
      "  --visualize           visualize features\n",
      "  --update              update all models\n",
      "  --project PROJECT     save results to project/name\n",
      "  --name NAME           save results to project/name\n",
      "  --exist-ok            existing project/name ok, do not increment\n",
      "  --line-thickness LINE_THICKNESS\n",
      "                        bounding box thickness (pixels)\n",
      "  --hide-labels         hide labels\n",
      "  --hide-conf           hide confidences\n",
      "  --half                use FP16 half-precision inference\n",
      "  --dnn                 use OpenCV DNN for ONNX inference\n",
      "  --vid-stride VID_STRIDE\n",
      "                        video frame-rate stride\n"
     ]
    }
   ],
   "source": [
    "!python ../../yolov5/detect.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a957aa-8830-4c39-bebb-9af1ade8dc19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
